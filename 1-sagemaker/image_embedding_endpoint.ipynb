{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada6a956",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "402a05be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.0.1 requires botocore<1.22.9,>=1.22.8, but you have botocore 1.26.10 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker ipywidgets --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d35cfc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker, boto3, json\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "aws_role = get_execution_role()\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11b83d0",
   "metadata": {},
   "source": [
    "## Select A Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db26f34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Dropdown\n",
    "\n",
    "# download JumpStart model_manifest file.\n",
    "boto3.client(\"s3\").download_file(\n",
    "    f\"jumpstart-cache-prod-{aws_region}\", \"models_manifest.json\", \"models_manifest.json\"\n",
    ")\n",
    "with open(\"models_manifest.json\", \"rb\") as json_file:\n",
    "    model_list = json.load(json_file)\n",
    "\n",
    "# filter-out all the Image Embedding models from the manifest list.\n",
    "image_embedding_models = []\n",
    "for model in model_list:\n",
    "    model_id = model[\"model_id\"]\n",
    "    if \"-icembedding-\" in model_id and model_id not in image_embedding_models:\n",
    "        image_embedding_models.append(model_id)\n",
    "\n",
    "# display the model-ids in a dropdown to select a model for inference.\n",
    "model_dropdown = Dropdown(\n",
    "    options=image_embedding_models,\n",
    "    value=\"tensorflow-icembedding-bit-m-r101x1-ilsvrc2012-featurevector-1\",\n",
    "    description=\"Select a model\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout={\"width\": \"max-content\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "164275bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b477a0e42947437c8d24527f3c0ba465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select a model', layout=Layout(width='max-content'), options=('tensorflow-icembedding-biâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45020943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model id: tensorflow-icembedding-efficientnet-b0-featurevector-1, model version: *=====\n"
     ]
    }
   ],
   "source": [
    "# model_version=\"*\" fetches the latest version of the model\n",
    "model_id, model_version = model_dropdown.value, \"*\"\n",
    "\n",
    "print(f'model id: {model_id}, model version: {model_version}=====')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcb27ca",
   "metadata": {},
   "source": [
    "## Retrieve JumpStart Artifacts & Deploy an Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3a6a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.serverless import serverless_inference_config\n",
    "\n",
    "\n",
    "endpoint_name = name_from_base(f\"jumpstart-example-infer-{model_id}\")\n",
    "\n",
    "inference_instance_type = \"ml.p2.xlarge\"\n",
    "\n",
    "# Retrieve the inference docker container uri. This is the base Tensorflow container image for the default model above.\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,  # automatically inferred from model_id\n",
    "    image_scope=\"inference\",\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "\n",
    "# Retrieve the inference script uri. This includes all dependencies and scripts for model loading, inference handling etc.\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, script_scope=\"inference\"\n",
    ")\n",
    "\n",
    "\n",
    "# Retrieve the model uri. This includes the model and model parameters.\n",
    "model_uri = model_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, model_scope=\"inference\"\n",
    ")\n",
    "\n",
    "\n",
    "# Create the SageMaker model instance\n",
    "model = Model(\n",
    "    image_uri=deploy_image_uri,\n",
    "    source_dir=deploy_source_uri,\n",
    "    model_data=model_uri,\n",
    "    entry_point=\"inference.py\",  # entry point file in source_dir and present in deploy_source_uri\n",
    "    role=aws_role,\n",
    "    predictor_cls=Predictor,\n",
    "    name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e06b1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "severless_config = serverless_inference_config.ServerlessInferenceConfig(memory_size_in_mb=1024, \n",
    "                                                                         max_concurrency=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f21fda6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "# deploy the Model. Note that we need to pass Predictor class when we deploy model through Model class,\n",
    "# for being able to run inference through the sagemaker API.\n",
    "model_predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    predictor_cls=Predictor,\n",
    "    endpoint_name=endpoint_name,\n",
    "    serverless_inference_config = severless_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ed27e",
   "metadata": {},
   "source": [
    "## Query endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02e866aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(model_predictor, image_file_name):\n",
    "    \"\"\"Query the model predictor.\"\"\"\n",
    "\n",
    "    with open(image_file_name, \"rb\") as file:\n",
    "        input_img_rb = file.read()\n",
    "\n",
    "    query_response = model_predictor.predict(\n",
    "        input_img_rb,\n",
    "        {\n",
    "            \"ContentType\": \"application/x-image\",\n",
    "            \"Accept\": \"application/json\",\n",
    "        },\n",
    "    )\n",
    "    return query_response\n",
    "\n",
    "\n",
    "def parse_response(query_response):\n",
    "    \"\"\"Parse response and return the embedding.\"\"\"\n",
    "\n",
    "    model_predictions = json.loads(query_response)\n",
    "    translation_text = model_predictions[\"embedding\"]\n",
    "    return translation_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e4768cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the embedding vector = 1280\n"
     ]
    }
   ],
   "source": [
    "img_name = 'images/0016fde3-0910-4cc1-8ef6-90e15f271073.jpg'\n",
    "query_response = query(model_predictor, img_name)\n",
    "embedding = parse_response(query_response)\n",
    "\n",
    "print(f'length of the embedding vector = {len(embedding)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e8bd9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=images/007bf018-a074-44df-80d7-70866f7bead8.jpg alt=images/007bf018-a074-44df-80d7-70866f7bead8.jpg align=\"left\" style=\"width: 250px;\"/><figcaption>First-5 elements of the feature vector (embedding) are: {-0.175242156, -0.0610245652, -0.121059008, -0.0657367781, -0.0291871876}</figcaption><figcaption>Total length of the feature vector (embedding) is: 1280</figcaption>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=images/020a5afe-fb13-4499-a1fa-8594d326eaa0.jpg alt=images/020a5afe-fb13-4499-a1fa-8594d326eaa0.jpg align=\"left\" style=\"width: 250px;\"/><figcaption>First-5 elements of the feature vector (embedding) are: {-0.045840919, -0.066641, 1.65105283, 1.88588369, -0.176540047}</figcaption><figcaption>Total length of the feature vector (embedding) is: 1280</figcaption>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=images/00096972-5f6b-44df-917b-f7d21ae5644c.jpg alt=images/00096972-5f6b-44df-917b-f7d21ae5644c.jpg align=\"left\" style=\"width: 250px;\"/><figcaption>First-5 elements of the feature vector (embedding) are: {-0.0415844731, 0.157631248, -0.111207433, -0.0583068393, 0.833677113}</figcaption><figcaption>Total length of the feature vector (embedding) is: 1280</figcaption>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=images/0016fde3-0910-4cc1-8ef6-90e15f271073.jpg alt=images/0016fde3-0910-4cc1-8ef6-90e15f271073.jpg align=\"left\" style=\"width: 250px;\"/><figcaption>First-5 elements of the feature vector (embedding) are: {-0.012213897, -0.169112384, 0.511228085, -0.0330246575, -0.151746809}</figcaption><figcaption>Total length of the feature vector (embedding) is: 1280</figcaption>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "import glob\n",
    "  \n",
    "for img_name in glob.glob('images/*'):\n",
    "    \n",
    "    query_response = query(model_predictor, img_name)\n",
    "    embedding = parse_response(query_response)\n",
    "    first_5element_embeddings = \"{\" + \", \".join([str(id) for id in embedding[:5]]) + \"}\"\n",
    "    display(\n",
    "        HTML(\n",
    "            f'<img src={img_name} alt={img_name} align=\"left\" style=\"width: 250px;\"/>'\n",
    "            f\"<figcaption>First-5 elements of the feature vector (embedding) are: {first_5element_embeddings}</figcaption>\"\n",
    "            f\"<figcaption>Total length of the feature vector (embedding) is: {len(embedding)}</figcaption>\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c1d887",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
