{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada6a956",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "402a05be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker ipywidgets --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d35cfc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker, boto3, json\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "aws_role = get_execution_role()\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11b83d0",
   "metadata": {},
   "source": [
    "## Select A Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db26f34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Dropdown\n",
    "\n",
    "# download JumpStart model_manifest file.\n",
    "boto3.client(\"s3\").download_file(\n",
    "    f\"jumpstart-cache-prod-{aws_region}\", \"models_manifest.json\", \"models_manifest.json\"\n",
    ")\n",
    "with open(\"models_manifest.json\", \"rb\") as json_file:\n",
    "    model_list = json.load(json_file)\n",
    "\n",
    "# filter-out all the Image Embedding models from the manifest list.\n",
    "image_embedding_models = []\n",
    "for model in model_list:\n",
    "    model_id = model[\"model_id\"]\n",
    "    if \"-icembedding-\" in model_id and model_id not in image_embedding_models:\n",
    "        image_embedding_models.append(model_id)\n",
    "\n",
    "# display the model-ids in a dropdown to select a model for inference.\n",
    "model_dropdown = Dropdown(\n",
    "    options=image_embedding_models,\n",
    "    value=\"tensorflow-icembedding-bit-m-r101x1-ilsvrc2012-featurevector-1\",\n",
    "    description=\"Select a model\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout={\"width\": \"max-content\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "164275bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7b94d4bd70450bb0c5fe170b3e3c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select a model', layout=Layout(width='max-content'), options=('tensorflow-icembedding-biâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45020943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model id: tensorflow-icembedding-efficientnet-b0-featurevector-1, model version: *=====\n"
     ]
    }
   ],
   "source": [
    "# model_version=\"*\" fetches the latest version of the model\n",
    "model_id, model_version = model_dropdown.value, \"*\"\n",
    "\n",
    "print(f'model id: {model_id}, model version: {model_version}=====')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcb27ca",
   "metadata": {},
   "source": [
    "## Retrieve JumpStart Artifacts & Deploy an Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3a6a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.serverless import serverless_inference_config\n",
    "\n",
    "\n",
    "endpoint_name = name_from_base(f\"jumpstart-example-infer-{model_id}\")\n",
    "\n",
    "inference_instance_type = \"ml.p2.xlarge\"\n",
    "\n",
    "# Retrieve the inference docker container uri. This is the base Tensorflow container image for the default model above.\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,  # automatically inferred from model_id\n",
    "    image_scope=\"inference\",\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "\n",
    "# Retrieve the inference script uri. This includes all dependencies and scripts for model loading, inference handling etc.\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, script_scope=\"inference\"\n",
    ")\n",
    "\n",
    "\n",
    "# Retrieve the model uri. This includes the model and model parameters.\n",
    "model_uri = model_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, model_scope=\"inference\"\n",
    ")\n",
    "\n",
    "\n",
    "# Create the SageMaker model instance\n",
    "model = Model(\n",
    "    image_uri=deploy_image_uri,\n",
    "    source_dir=deploy_source_uri,\n",
    "    model_data=model_uri,\n",
    "    entry_point=\"inference.py\",  # entry point file in source_dir and present in deploy_source_uri\n",
    "    role=aws_role,\n",
    "    predictor_cls=Predictor,\n",
    "    name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e06b1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "severless_config = serverless_inference_config.ServerlessInferenceConfig(memory_size_in_mb=1024, \n",
    "                                                                         max_concurrency=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f21fda6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!"
     ]
    }
   ],
   "source": [
    "# deploy the Model. Note that we need to pass Predictor class when we deploy model through Model class,\n",
    "# for being able to run inference through the sagemaker API.\n",
    "model_predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    predictor_cls=Predictor,\n",
    "    endpoint_name=endpoint_name,\n",
    "    serverless_inference_config = severless_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ed27e",
   "metadata": {},
   "source": [
    "## Query endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02e866aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(model_predictor, image_file_name):\n",
    "    \"\"\"Query the model predictor.\"\"\"\n",
    "\n",
    "    with open(image_file_name, \"rb\") as file:\n",
    "        input_img_rb = file.read()\n",
    "\n",
    "    query_response = model_predictor.predict(\n",
    "        input_img_rb,\n",
    "        {\n",
    "            \"ContentType\": \"application/x-image\",\n",
    "            \"Accept\": \"application/json\",\n",
    "        },\n",
    "    )\n",
    "    return query_response\n",
    "\n",
    "\n",
    "def parse_response(query_response):\n",
    "    \"\"\"Parse response and return the embedding.\"\"\"\n",
    "\n",
    "    model_predictions = json.loads(query_response)\n",
    "    translation_text = model_predictions[\"embedding\"]\n",
    "    return translation_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e4768cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the embedding vector = 1280\n"
     ]
    }
   ],
   "source": [
    "img_name = 'images/accessories-025ec8a0-0358-494f-a51a-065f090e84f8.jpg'\n",
    "query_response = query(model_predictor, img_name)\n",
    "embedding = parse_response(query_response)\n",
    "\n",
    "print(f'length of the embedding vector = {len(embedding)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e8bd9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=images/accessories-025ec8a0-0358-494f-a51a-065f090e84f8.jpg alt=images/accessories-025ec8a0-0358-494f-a51a-065f090e84f8.jpg align=\"left\" style=\"width: 250px;\"/><figcaption>First-5 elements of the feature vector (embedding) are: {-0.0641681, -0.121351697, -0.137552485, -0.0471454114, 0.752011299}</figcaption><figcaption>Total length of the feature vector (embedding) is: 1280</figcaption>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=images/floral-110f2a06-e151-4f79-9acb-8b8ce97ca449.jpg alt=images/floral-110f2a06-e151-4f79-9acb-8b8ce97ca449.jpg align=\"left\" style=\"width: 250px;\"/><figcaption>First-5 elements of the feature vector (embedding) are: {0.805973291, 0.701364875, 0.277170777, -0.070574455, -0.148900375}</figcaption><figcaption>Total length of the feature vector (embedding) is: 1280</figcaption>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=images/seasonal-0666855e-e1a2-446d-848e-864a92774721.jpg alt=images/seasonal-0666855e-e1a2-446d-848e-864a92774721.jpg align=\"left\" style=\"width: 250px;\"/><figcaption>First-5 elements of the feature vector (embedding) are: {0.0437648445, -0.111183047, -0.103441276, 0.439538658, -0.0964676291}</figcaption><figcaption>Total length of the feature vector (embedding) is: 1280</figcaption>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=images/tools-2aa46f50-0e73-40f4-92a2-fd5a7aec5a4d.jpg alt=images/tools-2aa46f50-0e73-40f4-92a2-fd5a7aec5a4d.jpg align=\"left\" style=\"width: 250px;\"/><figcaption>First-5 elements of the feature vector (embedding) are: {1.08455062, -0.0646940917, 0.164189398, -0.0661988333, 0.680954218}</figcaption><figcaption>Total length of the feature vector (embedding) is: 1280</figcaption>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=images/footwear-06acd586-2c90-486f-9a26-75ce1205e25f.jpg alt=images/footwear-06acd586-2c90-486f-9a26-75ce1205e25f.jpg align=\"left\" style=\"width: 250px;\"/><figcaption>First-5 elements of the feature vector (embedding) are: {-0.118220732, -0.124983683, -0.149069548, 0.125650704, 0.299451798}</figcaption><figcaption>Total length of the feature vector (embedding) is: 1280</figcaption>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=images/housewares-08301406-e647-4881-85ad-8134ba2ff1ce.jpg alt=images/housewares-08301406-e647-4881-85ad-8134ba2ff1ce.jpg align=\"left\" style=\"width: 250px;\"/><figcaption>First-5 elements of the feature vector (embedding) are: {-0.210215, -0.122170381, 0.270159, 0.258558899, -0.182575017}</figcaption><figcaption>Total length of the feature vector (embedding) is: 1280</figcaption>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "import glob\n",
    "  \n",
    "for img_name in glob.glob('images/*'):\n",
    "    \n",
    "    query_response = query(model_predictor, img_name)\n",
    "    embedding = parse_response(query_response)\n",
    "    first_5element_embeddings = \"{\" + \", \".join([str(id) for id in embedding[:5]]) + \"}\"\n",
    "    display(\n",
    "        HTML(\n",
    "            f'<img src={img_name} alt={img_name} align=\"left\" style=\"width: 250px;\"/>'\n",
    "            f\"<figcaption>First-5 elements of the feature vector (embedding) are: {first_5element_embeddings}</figcaption>\"\n",
    "            f\"<figcaption>Total length of the feature vector (embedding) is: {len(embedding)}</figcaption>\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c1d887",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
